<?xml version="1.0" encoding="utf-8"?>
<ul>
  <li>VertexShadlerD3D11_INPUT_ELEMENT_DESCinput_desc[]={//我们知道DXGI_FORMAT_R32G32B32_FLOAT是12字节的{"POSITION",0,DXGI_FORMAT_R32G32B32_FLOAT,0,0,D3D11_INPUT_PER_VERTEX_DATA,0},{"COLOR",0,DXGI_FORMAT_R32G32B32_FLOAT,0,12,D3D11_INPUT_PER_VERTEX_DATA,0},};CreateInputLayout(VERTEX::input_desc,std::size(VERTEX::input_desc),...);当我们在C++里面写入上述代码的时候,是告诉D3D11已”Position”和”Color”解析输入的Vertex数据。于是,我们将下面的数据传给D3D11:VERTEXOurVertices[]={//每组数据3*4+3*4=24字节{DirectX::XMFLOAT3{0.0f,0.5f,0.0f},DirectX::XMFLOAT3(1.0f,0.0f,0.0f)},{DirectX::XMFLOAT3{0.45f,-0.5,0.0f},DirectX::XMFLOAT3(0.0f,1.0f,0.0f)},{DirectX::XMFLOAT3{-0.45f,-0.5f,0.0f},DirectX::XMFLOAT3(0.0f,0.0f,1.0f)},};CreateBuffer(&amp;vertex_buf_);IASetVertexBuffers(vertex_buf_);关键字语义SemanticDescriptionPOSITIONAfloat4valuethatstoresposition.Itisusedtodenotethepositionofvertices,usually(butnotnecessarily)in3Dspace.COLORAfloat4valuethatstoredcolorSV_POSITIONAfloat4valuethatstoresposition.Itisusedtodenotethepositioninnormalizedscreencoordinates,not3Dcoordinates.SV_TARGETAfloat4valuetellingtheoutput-mergertodrawthegivencolorontherendertarget.//为什么是float4,而不是float3？搞不懂VOutVShader(float4position:POSITION,float4color:COLOR){VOutoutput;output.position=position;output.color=color;returnoutput;}float4PShader(float4position:SV_POSITION,#使用的是normailized坐标float4color:COLOR):SV_TARGET#返回值是给输出合并阶段的用的,输出到renderTarget上{returncolor;}</li>
  <li>WorldTransformation旋转缩放ViewTransformation世界坐标下的摄像机位置:根据摄像机位置转换坐标:ProjectionTransformation从摄像机视野转变为屏幕视野:以上的转换都是针对顶点坐标而言!</li>
  <li>神魔问题我真是服了噢,C++面试现在怎么是这个样子的，问的都是一些”神魔”的问题。构造函数可以调用虚函数么可以,但是没有意义。进入基类就是调用的基类函数,进入子类就是子类的函数析构函数可以调用虚函数么可以,同上。多继承的”缩型”问题多继承的虚函数表有意义的问题volatile真正的作用https://zhuanlan.zhihu.com/p/33074506###</li>
  <li>Vertex三角形的端点。D3D11中的顶点可以看成是三角形的端点坐标(x,y,z)以及这些点的属性。在D3D11中三角形是顺时针处理的。Primitives基元，3D环境中的一个元素,可以是三角形、线、点或者任何其他图形。D3DDEVICE代表一个VideoAdapter(device要从指定的adapter上创建)。D3D11DeviceContext代表GPU的渲染管线.资源和资源视图资源是场景的构建基块：几何图形、纹理、着色器数据。资源可以以常规用途内存格式存储，以便可以由多个管道阶段共享。管道阶段使用视图解释资源数据。资源视图在概念上类似于强制转换资源数据，以便它可以在特定上下文中使用。因此,资源不能被直接绑定到一个管线阶段,必须为资源创建资源视图(将资源类型化)，然后绑定到管线上。举个例子：ID3D11Resource*backBufferResource;hr=swap_chain_-&gt;GetBuffer(0,__uuidof(ID3D11Resource),(void**)&amp;backBufferResource);if(FAILED(hr)){LOG_ERROR("IDXGISwapChain::GetBufferfailed,err:%x",hr);returnfalse;}hr=d3d11_dev_-&gt;CreateRenderTargetView(backBufferResource,nullptr,&amp;render_view_);目的是将”数据”换到backbuffer上,但是backbuffer是一个资源,所以需要创建backbuffer的视图。通过”D3D11_RENDER_TARGET_VIEW_DESC”来描述,这里传了nullptr(accessesallofthesubresourcesinMipmaplevel0)Mipmap的通俗解释。画一个三角形定义VERTEX结构CPU部分structVERTEX{DirectX::XMFLOAT3pos;DirectX::XMFLOAT4Color;};//astructtodefineavertex//createatriangleusingtheVERTEXstructVERTEXOurVertices[]={{DirectX::XMFLOAT3{0.0f,0.5f,0.0f},DirectX::XMFLOAT4(1.0f,0.0f,0.0f,1.0f)},{DirectX::XMFLOAT3{0.45f,-0.5,0.0f},DirectX::XMFLOAT4(0.0f,1.0f,0.0f,1.0f)},{DirectX::XMFLOAT3{-0.45f,-0.5f,0.0f},DirectX::XMFLOAT4(0.0f,0.0f,1.0f,1.0f)}};D3D11_BUFFER_DESCbd;ID3D11Buffer*pVBuffer=nullptr;d3d11_dev_-&gt;CreateBuffer(&amp;bd,NULL,&amp;pVBuffer);//createthebuffer通过上述代码,我们创建了一个buffer(就是一个数据块),那么GPU如果解析这个数据块呢?GPU部分voidinit(){//告诉GPU,输入数据应该如何解析constD3D11_INPUT_ELEMENT_DESCinput_desc[2]={{"POSITION",0,DXGI_FORMAT_R32G32B32_FLOAT,0,0,D3D11_INPUT_PER_VERTEX_DATA,0},{"COLOR",0,DXGI_FORMAT_R32G32B32A32_FLOAT,0,12,D3D11_INPUT_PER_VERTEX_DATA,0},};ID3D11InputLayout*layout=nullptr;d3d11_dev_-&gt;CreateInputLayout(VERTEX::input_desc,std::size(VERTEX::input_desc),blob-&gt;GetBufferPointer(),blob-&gt;GetBufferSize(),&amp;layout);d3d11_ctx_-&gt;IASetInputLayout(layout);}voidrender(){constfloatclear[4]={0.f,0.2f,0.4f,1.f};d3d11_ctx_-&gt;ClearRenderTargetView(render_target_view_,clear);//为什么每一帧都要绑定:seeremark//https://learn.microsoft.com/en-us/windows/win32/api/d3d11/nf-d3d11-id3d11devicecontext-omsetrendertargetsd3d11_ctx_-&gt;OMSetRenderTargets(1,render_view_.GetAddressOf(),nullptr);//这里不能直接&amp;render_view_,会导致render_view_=nullptr//使用哪些"Vertex"UINTstride=sizeof(VERTEX);UINToffset=0;d3d11_ctx_-&gt;IASetVertexBuffers(0,1,&amp;vertex_buffer_,&amp;stride,&amp;offset);//使用这些"Vertex"画什么形状d3d11_ctx_-&gt;IASetPrimitiveTopology(D3D10_PRIMITIVE_TOPOLOGY_TRIANGLELIST);//画三个顶点,从第0个开始d3d11_ctx_-&gt;Draw(3,0);//上屏swapchain_-&gt;Present(0,0);}注意事项全屏模式下无法关闭,因此在退出D3D11的时候需要先切换到窗口模式</li>
  <li>TheInputAssemblerStage管线的第一个阶段,用来收集数据,为后续做准备。FunctionDescriptionIASetVertexBuffersTellstheinput-assemblerwhichvertexbuffertoreadfrom.IASetIndexBufferThisisanewone,andwillbecoveredintheMovingto3Dtutorial.IASetInputLayoutTellstheinput-assemblertheexpectedlayoutofvertexdataineachvertex.IASetPrimitiveTopologyTellstheinput-assemblerwhattypeofprimitive(suchastriangle-strip,line-list,etc.)VertexProcessing当输入装配阶段完成后,随之6个阶段:VertexShaderStageHullShaderStageTessellatorStageDomainShaderStageGeometryShaderStageStreamOutputStage只有VertexShaderStage是必须的,其他都是可选。PixelProcessingRasterizerStagePixelShaderStage光栅化是个固定的流程,只有PixelShader阶段是可以编程的。Output-MergerStage通过像素着色器生成的像素片段会被移送至渲染管线的输出合并阶段。在这个阶段中，一些像素片段需要经过模板测试和深度测试来确定是否能留下，然后必要的时候还需要与绑定的缓冲区对应像素片段进行混合操作，可以实现透明等效果。顶点处理过程顶点着色器是管线的第二阶段，能够修改单个顶点的属性。它通常用于将3D坐标转换为屏幕坐标，但也可以更改其他属性。着色器是一个”函数”,对每一个顶点都会执行一遍(GPU是并行计算的,不用担心性能),随后执行这三个阶段:HullShaderStageTessellatorStageDomainShaderStageGeometryShaderStage这是一个可选阶段,和顶点着色器不同的是,它不针对顶点而是”Primitives”(三角形)。输入一个三角形,输出一个三角形。StreamOutputStage略像素处理过程Onceaprimitive’sverticeshavebeenplacedinscreencoordinates,theGPUthenrendersthepixels.First,itrunstheverticesthroughtherasterizerstage,whichdetermineswhatpixelsaregoingtoberendered.Second,itrunseachpixelthroughapixelshader,whichallowsyoutoalterthecoloranddepth(distancefromthescreen)ofeachpixel.RasterizerStage光栅化阶段决定使用哪些顶点去绘制”Pirmitive”使用下面的代码告诉”Raster”使用backbuffer上的哪个范围内的Pixels//SettheviewportD3D11_VIEWPORTviewport;ZeroMemory(&amp;viewport,sizeof(D3D11_VIEWPORT));viewport.TopLeftX=0;viewport.TopLeftY=0;viewport.Width=width*1.0f;viewport.Height=height*1.0f;d3d11_ctx_-&gt;RSSetViewports(1,&amp;viewport);PixelShader着色器是一个”函数”,对每一个像素都会执行一遍(GPU是并行计算的,不用担心性能)。Therasterizerstageplaysanimportantpartinthepixelshader’sinputs.It’sjobistogiveinformationspecifictothatpixel.注:“颜色减半”这个操作使用顶点着色器更快，这里只是做个示例。PixelShader不能改变”坐标”!输出合并阶段当像素片段由像素着色器生成之后，它们会被传送到渲染管线的输出合并（outputmerger，简称OM）阶段。在该阶段中，某些像素片段会被丢弃（例如，未能通过深度测试或模板测试）。未丢弃的像素片段会被写入后台缓冲区。混合（blending）工作是在该阶段中完成的，一个像素可以与后台缓冲区中的当前像素进行混合，并以混合后的值作为该像素的最终颜色。某些特殊效果，比如透明度，就是通过混合来实现的；我们会在第9章专门讲解混合。</li>
  <li>士兵突击«conquestofparadise»人总是要分的，而且还会越分越远，想的你抓心挠肺的。可是咱也在长啊，个越来越高，能耐越来越大，总有一天你会发现，到时候你想见谁就见谁，从天南到海北也就一抬腿的距离。报告，我是钢七连第四千九百五十六个兵。光荣在于平淡，艰巨在于漫长。</li>
  <li>QT的Widget尺寸策略QSizePolicy::Fixed只能使用sizeHint的大小,任何操作都不会改变控件大小QSizePolicy::MinimumsizeHint为最小大小,控件可以被拉伸QSizePolicy::MaximumsizeHint为最大大小,控件可以被压缩QSizePolicy::PreferredsizeHint为建议大小,控件既可以被压缩也可以被拉伸QSizePolicy::MinimumExpandingsizeHint为最小大小,不能被压缩,被拉伸的优先级更高QSizePolicy::ExpandingsizeHint为建议大小,可以被压缩,被拉伸的优先级更高QSizePolicy::IgnoredsizeHint的值将会被忽略QT加载资源文件QT加载样式表</li>
  <li>背景在linux下编写网络包过滤程序的时候，希望内核只投递指定规则的报文。概要主要是记录如何分析bpffilter的规则码。tcpdump生成bpfcodetcpdump-iloipandudpanddstport65500-d如下:(000)ldh[12]#加载第12字节的word(001)jeq#0x800jt2jf10#判断是否是ipv4,分别跳转到2或10(002)ldb[23]#加载23字节(003)jeq#0x11jt4jf10#判断是否是udp(17),分别跳转(004)ldh[20]#加载第20字节的word(005)jset#0x1fffjt10jf6#分析是否出现了frament(分包)(006)ldxb4*([14]&amp;0xf)#计算ip头部长度(007)ldh[x+16]#取ip后的第16字节(word),udp源端口(008)jeq#0xffdcjt9jf10#判断源端口是否是65500(009)ret#262144#match(010)ret#0#discard通过-dd参数产生具体的structsock_filter结构的数据:tcpdump-iloipandudpanddstport65500-dd注意点创建rawsocket的时候需要指定收包是从数据链路层开始，还是从ip开始。使用上述的规则码的时候，必须是从数据链路层开始，即:intfd=::socket(PF_PACKET,SOCK_RAW,htons(ETH_P_IP));如果intfd=::socket(PF_PACKET,SOCK_DGRAM,htons(ETH_P_IP));那么就需要自行修改这个规则码，将所有的”地址”减去14（一般来说是以太网，以太网帧头部长14字节）.知道了上述规则后，就具备了修改code的能力。</li>
  <li>抽帧分为fps过高抽帧和实际编码码率过高抽帧,这里先讨论fps过高引起的抽帧.需求视频输入是0-60帧,基于某些原因需要精确控制输出fps的值.模型如下:视频帧输入——-&gt;抽帧——–&gt;输出到编码器比如,输入fps=60,目标输出fps=30.这个时候就存在2种完全不同的方法:定时器33ms醒来一次,取最新更新出的输入帧(需要缓存在某个地方)送去输出每隔2个输入,产生一个输出方法1的好处是可以非常平滑且精确的控制输出FPS,但是存在延迟(输入没法立即送去输出).方法2几乎没有延迟,输入可以立刻送去输出.问题在于如何完成”跳帧”的判断(上例中的”每隔2个输入”)当out-fps不是in-fps的整数倍,或者out-fps&lt;in-fps的时候如何处理.考虑当前代码结构和性能问题,必须选择方法2.计算实时fps一个很自然的想法是使用一个1秒长度的窗口去”盖住”历史,计算窗口内的记录.如下图:在T0点的FPS=4.如果输入是均匀的情况1:in-fps大于out-fps例:输入fps=10,目标fps=7为了解释算法是如何工作的,需要先假设上一秒内算法工作的很好(保留下了相对均匀的7帧)进入第二秒后,该窗口”盖住”了8帧,如果允许这一帧输出,那么输出FPS=8&gt;7,因此需要将该帧丢弃紧接着,在下一帧输入的时候继续判断,窗口”盖住”了7帧,符合,将该帧送去输出.按照这个方式,输入的10帧会被每隔2-3帧丢掉1帧,最终只留下7帧.情况2:in-fps小于out-fps例:输入fps=10,目标fps=15任何时刻窗口”盖住”的帧都不会超过15(最多等于10),因此不会丢弃任何输入帧.如果输入是不均匀的例:输入fps=20,目标fps=5为了解释问题是如何产生的,仍旧需要先假设上一秒内算法工作的很好(保留了5帧):进入第二秒后,输入的视频帧不均匀,主要集中在后半段,按照之前的运行机制抽帧后会在后半段保留4帧,前半段保留一帧,这是没有问题的(因为输入本身就不均匀):进入第三秒后,输入的视频帧变得均匀:但是上一秒的后半段已经输出了4帧,导致这一秒的前半段只能产生1帧,并且在后半段连续输出4帧:这时候因为这个机制导致了:输入是均匀的,输出却变成了不均匀并且无限循环下去.解决(缓解)方式目前的做法:计算fps的时候,不仅统计过去1秒的视频帧数量n1,还统计过去250ms的视频帧数量n2最终的:\[fps=max({n1,\frac{n2*1000}{250}})\]但是这种做法会导致第一个周期后半段的输出不足4帧,并且仍旧会有小卡顿.其它方法:将固定的1000ms窗口改为”500ms-1000ms”内的随机数,每次都重新产生.这种方法能够将”聚集”逐渐打散(还没试)</li>
  <li>卡尔曼增益简单介绍及推导有一把尺子测量一枚硬币的直径,记录每次测量出的结果(测量值):$x_1$,$x_2$,$x_3$,….那么,对硬币直径的估计值:$\overline{x}_n$=$\frac{(x_1+x_2+x_3+...+x_n)}{n}$进一步,写成递归形式:$\overline{x}_n$=$\overline{x}_{n-1}$+$\frac{1}{n}(x_n-\overline{x}_{n-1})$可见,随着${n\to+\infty}$,测量结果已经不再重要.文字表示为:当前的估计值=上一次的估计值+系数*(当前的测试量-上一次的估计值)假设要考虑上一次的估计误差和本次的测量误差,一个很直观的想法就是:如果估计误差大于测量误差,也就是说测量的更佳准确,那么当前的估计值应该偏向于本次的测量值如果估计误差小于测量误差,也就是说测量的不准确,那么当前的估计值应该偏向于上一次的估计值这就是数据融合的思想,此时,这个系数就是卡尔曼增益系数:\[G=\frac{估计误差}{估计误差+测量误差}\]对于一个确定性离散时间系统的状态方程:$x_{n+1}=Ax_n+Bu_k+w_k$,$w_k$表示过程噪声$y_n=Cx_n+v_k,v_k$表示测量误差那么，从数据融合的角度看，对于状态的估计其实就是:\[\overline{x}_{n+1}=\overline{x}^{calc}_{n}+G(\overline{x}^{mess}_n-\overline{x}^{calc}_n)\]进一步，对G做转换:\[G=KC\]我们称K是可以将测量值转换为真实值的卡尔曼增益,从而有:\[\overline{x}_{n+1}=\overline{x}^{mess}_{calc}+K(y_k-C\overline{x}^{calc}_n)\]那么，误差就可以表示为:\(e_n=x_n-\overline{x}_n\)\[=x_n-\overline{x}^{calc}_n-K(Cx_n+v_k)+KC\overline{x}^{calc}_n\]\[=(I-KC)x_n-(I-KC)\overline{x}^{calc}_n-Kv_n\]\[=(I-KC)(x_n-\overline{x}^{calc}_n)-Kv_n\]上述中的I代表单位矩阵，如果是1阶就是1，二阶则是2X2的单位矩阵需要假设这个误差满足正太分布:\[e\simN(0,P_k)\]$P_k$就是随机变量的方差，对于多维随机变量来说就是指协方差矩阵,可以表示为:\[P_k=E[e_k*e^t_k],(e^t表示矩阵的转置)(证明略)\]代入各式:\[P_k=E{(I-KC)(x_k-x^{calc}_k)-Kv_k}{(I-KC)(x_k-x^{calc}_k)-Kv_k}^T\]将乘积展开，同时引入估计误差\[e_k=x_k-x^{calc}_{k},则有\]\[P_k=(I-KC)E[e_k*e^t_k](I-KC)^t+KE[v_k*v^t_k]K^t\]注意，上式中的$e_k$代表的是估计误差,将$E[e_k*e^t_k]记作\overline{P}_k$从而:\[P_k=(\overline{P}_k-KC\overline{P}_k)(I-C^tK^T)+KRK^t,R=E[v_k*v^t_k]\]我们要让误差最小,就是要让导数为0（且二次导小于0）,矩阵的求导过程略:\[\frac{dP_k}{dK}=K(CP_kC^t+R)-P_kC^t=0\]\[K=\frac{P_kC^t}{CP_kC^t+R}\]信道速率+排队时延的估计webrtc认为帧的抖动被认为是帧大小的变化引起的:\[delay=Rate_{channel}*Delta_{frame}+Noise,即信道速率*帧大小的变化+噪声\]webrtc使用卡尔曼滤波去估计信道速率和排队延迟,从而进一步确定jitter首先，建立数学模型，这是个二元系统，信道速率(R)+排队延迟(D)。从模型上说，这两个值当然是不变的，也即\[R_k=1*R_{k-1}+0\]\[D_k=1*D_{k-1}+0\]系统的状态转换方程用矩阵可以表示为\[\begin{bmatrix}R\\D\\\end{bmatrix}=\begin{bmatrix}1&amp;&amp;0\\0&amp;&amp;1\\\end{bmatrix}*\begin{bmatrix}R_{k_1}&amp;&amp;D_{k-1}\\\end{bmatrix}\]系统输出(只有一个jitter)\[jitter=deltaF*R+D\]用矩阵表示为:\[\begin{bmatrix}jitter\\\end{bmatrix}=\begin{bmatrix}deltaF&amp;&amp;1\\\end{bmatrix}*\begin{bmatrix}R\\D\\\end{bmatrix}\]下面引入一条卡尔曼滤波中的公式，先验的误差协方差矩阵(证明略，还没学会):\(P_k=AP_{k-1}A^T+Q\)\(Q=E[w_k*w^t_k],过程噪声的协方差矩阵\)A就是系统的转换矩阵,那么就有:\[P_k=AP_{k-1}A^T+Q\begin{bmatrix}1&amp;&amp;0\\0&amp;&amp;1\\\end{bmatrix}*P_{k-1}*\begin{bmatrix}1&amp;&amp;0\\0&amp;&amp;1\\\end{bmatrix}+Q=P_{k-1}+Q\]这时候，再看webrtc中的代码://Prediction//M=M+Q_thetaCov[0][0]+=_Qcov[0][0];_thetaCov[0][1]+=_Qcov[0][1];_thetaCov[1][0]+=_Qcov[1][0];_thetaCov[1][1]+=_Qcov[1][1];一样一样的。接着更新卡尔曼增益系数(第一部分已经给出证明):\(K=\frac{P_kC^t}{CP_kC^t+R}\)\[C=\begin{bmatrix}deltaF&amp;&amp;1\end{bmatrix},前面已经给出\]再对应源码,注意是二阶（R,D）:Mh[0]=_thetaCov[0][0]*deltaFSBytes+_thetaCov[0][1];Mh[1]=_thetaCov[1][0]*deltaFSBytes+_thetaCov[1][1];//sigmaweightsmeasurementswithasmalldeltaFSasnoisyand//measurementswithlargedeltaFSasgoodif(_maxFrameSize&lt;1.0){return;}doublesigma=(300.0*exp(-fabs(static_cast&lt;double&gt;(deltaFSBytes))/(1e0*_maxFrameSize))+1)*sqrt(_varNoise);if(sigma&lt;1.0){sigma=1.0;}hMh_sigma=deltaFSBytes*Mh[0]+Mh[1]+sigma;if((hMh_sigma&lt;1e-9&amp;&amp;hMh_sigma&gt;=0)||(hMh_sigma&gt;-1e-9&amp;&amp;hMh_sigma&lt;=0)){assert(false);return;}kalmanGain[0]=Mh[0]/hMh_sigma;kalmanGain[1]=Mh[1]/hMh_sigma;接下去，计算得到本次的最优估计值://Correction//theta=theta+K*(dT-h*theta)measureRes=frameDelayMS-(deltaFSBytes*_theta[0]+_theta[1]);_theta[0]+=kalmanGain[0]*measureRes;_theta[1]+=kalmanGain[1]*measureRes;继续引进卡尔曼公式2,更新先验误差协方差矩阵(证明略，还没有学会):\[P_{k+1}=(I-KH)P_k\]对应源码://M=(I-K*h)*Mt00=_thetaCov[0][0];t01=_thetaCov[0][1];_thetaCov[0][0]=(1-kalmanGain[0]*deltaFSBytes)*t00-kalmanGain[0]*_thetaCov[1][0];_thetaCov[0][1]=(1-kalmanGain[0]*deltaFSBytes)*t01-kalmanGain[0]*_thetaCov[1][1];_thetaCov[1][0]=_thetaCov[1][0]*(1-kalmanGain[1])-kalmanGain[1]*deltaFSBytes*t00;_thetaCov[1][1]=_thetaCov[1][1]*(1-kalmanGain[1])-kalmanGain[1]*deltaFSBytes*t01;至此，一轮卡尔曼滤波结束.end本文详细证明了卡尔曼滤波算法公式中的卡尔曼增益系数，以及说明了系统转换方程、测量方程。对于先验误差公式以及误差协方差的更新公式未给出证明。并且未对webrtc中如何deltaF、noise进行说明(比较简单)。参考链接:https://zhuanlan.zhihu.com/p/33899560https://www.cnblogs.com/heguanyou/p/7502909.htmlhttps://zhuanlan.zhihu.com/p/165570020</li>
  <li>lea指令lea指令的解释是:loadeffectiveaddress.网上有很多解释,比如知乎高赞汇编语言中mov和lea的区别有哪些？:lea是“loadeffectiveaddress”的缩写，简单的说，lea指令可以用来将一个内存地址直接赋给目的操作数，例如：leaeax,[ebx+8]就是将ebx+8这个值直接赋给eax，而不是把ebx+8处的内存地址里的数据赋给eax。而mov指令则恰恰相反，例如：moveax,[ebx+8]则是把内存地址为ebx+8处的数据赋给eax。说的没错,可是仍旧是没有解释为什么用mov就不行,比如:leaeax,[ebx+8];将ebx+8这个值直接赋给eax难道不等价与:moveax,ebx+8;其实,这才是初学者真正想问的问题.原因也很搞笑:mov指令不支持这样的格式.上面的例子中,源操作数”ebx+8”isinvalid.</li>
  <li>###notes在8086处理器上,如果要用寄存器来提供偏移地址,只能使用BX,si,di,bP,不能使用其它寄存器.以下指令是非法的:mov[ax],dl8086处理器只支持以下几种基地址寄存器和变址寄存器的组合:[bx+si][bx+di][bp+si][bp+di]条件转移指令js当SF==1则跳转,jns与之相反jz当zF==1则跳转,jnz与之相反jo当OF==1则跳转,jno与之相反jc当CF==1则跳转,jnc与之相反jp当PF==1则跳转,jnp与之相反常用指令movsb|movswDS:SI--&gt;ES:DIDF=0low-&gt;highDF=1high-&gt;lowinstruction'cld'cancleardfdivA/B.A是被除数,B是为除数.被除数A默认存在AX中,或者AX和DX中(DX存高x位)如果除数是8位，那么除法的结果AL保存商，AH保存余数.如果除数16位，那么除法的结果AX保存商，DX保存余数。cli&amp;&amp;sti清除和设置IF(中断标志位)repe/repne相等(ZF==0)/不相等的时候重复scasb(w|d)两个对比数分别为EAX/AX/AL和DS:EDI,并且将edi-+1（2|4)retret弹栈到IP寄存器retf弹栈到IP,再弹栈到CSiret弹栈到IP,再弹栈到CS,再弹栈到FLAGScall指令call指令有三种形式:第一种是16位相对近调用,近调用的意思是被调用的目标过程位于当前代码段内,而非另一个不同的代码段,所以只需要得到偏移地址即可.16位相对近调用是三字节指令,操作码为0xE8.在指令执行阶段,处理器看到操作码0xE8,就知道它应当调用一个过程.于是,它用指令指针寄存器IP的当前内容加上指令中的操作数,再加上3,得到一个新的偏移地址.接着将IP的原有内容压入栈.最后,用刚才的偏移地址取代IP原油的内容.这直接导致处理器的执行流程转移到目标位置处.第二种是16位间接绝对近调用,这种调用也是近调用,只能调用当前代码段内的过程,指令中的操作数不是偏移量,而是被调用过程的真实偏移地址,故称绝对地址.这个地址不是直接出现在指令中,而是由16位的通用寄存器或者16位的内存单元简介给出.第三种是16位直接绝对远调用,调用另一个代码段内的过程.比如:call0x20000:0x0030如果被调用过程处于当前代码段,也没关系.第四种是16位间接绝对远调用,这也属于段间调用,被调用过程属于另一个代码段.比如:callfar[0x2000]callfar[bx]间接远调用必须使用far.中断实模式下,处理器要求中断向量表需要存放在物理地址0x00000-&gt;0x003ff,同1k的空间内,共256个中断,每个中断向量4个字节.0x00000...-&gt;....0x003ff---------------------------------------------偏移地址(2字节)|段地址(2字节)|偏移地址..---------------------------------------------内联汇编常用约束r:Register(s)a:%eax,%ax,%alb:%ebx,%bx,%blc:%ecx,%cx,%cld:%edx,%dx,%dlS:%esi,%siD:%edi,%dii:直接操作数=:只写函数调用寄存器约定rax-temporaryregister;whenwecallasyscal,raxmustcontainsyscallnumberrdi-usedtopass1stargumenttofunctionsrsi-pointerusedtopass2ndargumenttofunctionsrdx-usedtopass3rdargumenttofunctionsrcx-fourthargumentr8-fifthargumentr9-sixthstack-oversixth待整理栈RBPisthebasepointerregister.Itpointstothebaseofthecurrentstackframe.RSPisthestackpointer,whichpointstothetopofcurrentstackframe.twooperators:pushargument-incrementsstackpointer(RSP)andstoresargumentinlocationpointedbystackpointerpopargument-copieddatatoargumentfromlocationpointedbystackpointer段data-sectionisusedfordeclaringinitializeddataorconstantsbss-sectionisusedfordeclaringnoninitializedvariablestext-sectionisusedforcode以sys_write为例:size_tsys_write(unsignedintfd,constchar*buf,size_tcount);section.datamsgdb"hello,world!";db代表声明单字节类型的section.textglobal_start_start:movrax,1;sys_write调用号movrdi,1;stdcoutmovrsi,msgmovrdx,13syscallmovrax,60movrdi,0syscall简单程序示例section.data;Defineconstantsnum1:equ100num2:equ50;initializemessagemsg:db"correct"section.textglobal_start;;entrypoint_start:;setnum1'svaluetoraxmovrax,num1;setnum2'svaluetorbxmovrbx,num2;getsumofraxandrbx,andstoreit'svalueinraxaddrax,rbx;compareraxand150cmprax,150;goto.exitlabelifraxand150arenotequaljne.exit;goto.rightSumlabelifraxand150areequaljmp.rightSum;Printmessagethatsumiscorrect.rightSum:;;writesyscallmovrax,1;;filedescritor,standardoutputmovrdi,1;;messageaddressmovrsi,msg;;lengthofmessagemovrdx,8;;callwritesyscallsyscall;exitfromprogramjmp.exit;exitprocedure;exitsyscallmovrax,60;exitcodemovrdi,0;callexitsyscallsyscall声明initialized:equ(equate)similartoC’sdefinedbdefineandallocateabyte,dw,dd,dt,do,dyanddznoninitializedvariables:RESB,RESW,RESD,RESQ,REST,RESO,RESYandRESZ简单程序示例%macroPRINT1pushapushfjmp%%astr%%strdb%1,0%%strlnequ$-%%str%%astr:_syscall_write%%str,%%strlnpopfpopa%endmacro%macro_syscall_write2movrax,1movrdi,1movrsi,%%strmovrdx,%%strlnsyscall%endmacroAT&amp;T语法.data//initializeddatadefinition.text.global_start_start://mainroutinedatadefinition.section.data//1bytevar1:.byte10//2bytevar2:.word10//4bytevar3:.int10//8bytevar4:.quad10//16bytevar5:.octa10//assembleseachstring(withnoautomatictrailingzerobyte)intoconsecutiveaddressesstr1:.asci"Helloworld"//justlike.ascii,buteachstringisfollowedbyazerobytestr2:.asciz"Helloworld"//Copythecharactersinstrtotheobjectfilestr3:.string"Helloworld"oprandsorder;movesource,destinationmovw$10,%axGNUassemblerhas6postfixesforoperations:b-1byteoperandsw-2bytesoperandsl-4bytesoperandsq-8bytesoperandst-10bytesoperandso-16bytesoperandsThisruleisotonlymovinstruction,butalsoforallanotherlikeaddl,xorb,cmpwandetc…</li>
  <li>Probewebrtc使用gcc（googlecongestioncontrol）来估计带宽，控制当前的发送速度。gcc中基于丢包和基于延迟的算法有个特点：1.能迅速响应带宽的衰减2.不能迅速响应带宽的增加举个例子，如果当前带宽是20mbps，由于其它因素，带宽骤降至15mbps，gcc能快速的给出over-using信号(rtt为10ms环境下，响应速度是100-200ms)。如果当前带宽是20mbps，由于其它因素，带宽升至了25mbps，依赖gcc自身的调整的话需要几十秒的时间（加性增减性乘的效果）。由于以上的原因，如果从0bps开始运行gcc算法（纯算法本身），要达到一定的带宽需要太长的时间。webrtc中有一个用来在起始阶段（或周期性）迅速探测到当前带宽的措施—就是Probe模块，和TCP的慢启动比较像啦！原理Probe的原理简单说起来就是这样的：发送端以一定的速度发送数据包，同时记录这些数据包的发送时间、序列号（全局唯一）、探测组的id.接收端每过一段时间（50-150ms）会反馈数据包的到达时间，就像这样：s_t表示发送时间、r_t标识接受时间，这样我们就知道了发送速度、接收速度://发送端发送这些数据包的时间间隔common::TimeDeltasend_interval=common::TimeDelta(state.last_send-state.first_send);//接收端接收这些数据包的时间间隔common::TimeDeltarecive_interval=common::TimeDelta(state.last_recive-state.first_recive);//发送的字节数(已发送的字节减去最后一个数据包的字节，不难理解吧?)size_tsize_send=state.size_total_sent-state.size_last_sent;//接收端收到的字节数(已接收的字节减去第一个数据包的字节，不难理解吧?)size_tsize_recive=state.size_total_recived-state.size_first_recived;//从而就得到了双方的速度common::DataRatesend_bps=1_bps*(size_send*8/(send_interval/1_sec));common::DataRatereceive_bps=1_bps*(size_recive*8/(recive_interval/1_sec));我们定义S1为发送速度，R1为接收速度，那么可以认定当前的网络带宽至少是min(S1,R1)。在这里涉及到几个问题：如何控制发送端的速度探测包的大小如果设置才会比较合理探测应该持续多久，尽可能的避免对正常数据的影响控制探测速度、包大小、探测时长webrtc中探测包是通过一个定时器来控制速度的。假设我们需要探测的目标速度是10mbps，探测时间是10ms，那么我们总共需要发送的所有探测包的总大小total_bytes=10mbps*15ms/8;第一个探测包的大小取值为bytes1=10_mbps*1_ms/8，立即发送。为了控制速度，我们需要考虑第二个探测包的发送时间，假设是dt时间后发送，计算dt:dt=sent_bytes*8/1_mbps;意思就是已发送比特数除以目标码率，在dt的时间后发送第二个探测包，这样我们就精确地控制了发送速度就是我们希望的速度。以这种方式发送数据包，直到”已发送字节”大于等于total_bytes，该轮探测结束。上述中15ms就是探测需要持续的时间(可以自定义)，bytes1就是探测包的大小(通过修改”1_ms”可以自定义大小)通过一定的手段，我们可以将正常数据流上的数据包变为探测包，减少对正常数据流的影响。探测一般都是已当前速度的几倍去发送数据，所以必不可免的会影响当前的数据流，可以修改”15_ms”来自定义探测时长。乘性探测为了快速的探测到实际带宽的大致值，使用乘性探测。举个例子，假设起始速度设置为450kbps，那么探测速度就设置为900kbps，如果探测结果在900kbps*0.7=630kbps以上，继续向上探测，探测速度是1.8mbps，如果第二次探测结果在1.8mbps*0.7以上，继续向上探测，探测速度是3.6mbps…..直到某一个探测结果不符合“0.7以上”，那么就判定链路带宽应该在此次探测结果附近。然后，以这个速度发送数据流，在这个基础上运行gcc算法，通过延迟梯度和丢包来控制发送码率。实际情况在我的实现中。在rtt10ms的环境下，可以立刻探测到带宽上限。运行日志如下：probesuccessful,sendspeed:892.845kbps,receivespeed:898.797kbpsprobesuccessful,sendspeed:888.780kbps,receivespeed:891.707kbpsprobesuccessful,sendspeed:1.771mbps,receivespeed:1.628mbpsprobesuccessful,sendspeed:1.777mbps,receivespeed:2.214mbpsprobesuccessful,sendspeed:3.358mbps,receivespeed:3.337mbpsprobesuccessful,sendspeed:3.521mbps,receivespeed:3.591mbps...probesuccessful,sendspeed:30.376mbps,receivespeed:31.149mbpsprobesuccessful,sendspeed:59.897mbps,receivespeed:45.238mbps(达到带宽上限)则认为当前带宽的上限是45.238mbps(我通过tc命令设置的带宽就是45mbps，探测结果非常的准)从300kbps的起始速度上升到45mbps，用时800ms。在实际环境中，webrtc就是通过该机制在起始阶段迅速的”跳跃”到一个合适的码率上。解答meemetao@gmail.com</li>
  <li>template&lt;typenameT&gt;classshared_ptr{public:shared_ptr&lt;T&gt;(T*t){set_ptr(this,t);}};template&lt;typenameT&gt;classenable_shared_from_this{public:shared_ptr&lt;T&gt;shared_from_this(){//ifsp_notnullreturnsp_;}voidset_ptr(shared_ptr&lt;T&gt;p){sp_=p;}private:shared_ptr&lt;T&gt;sp_;//FIXME:weak_ptr};template&lt;typenameT&gt;voidset_ptr(shared_ptr&lt;T&gt;t,enable_shared_from_this&lt;T&gt;*e){e-&gt;set_ptr(t);}voidset_ptr(...){//donothing}classt:publicenable_shared_from_this&lt;t&gt;{public:t()=default;};当使用shared_ptr创建t对象时,t对象内部通过set_ptr将这个share_ptr对象包含在自己内部。但是这样子的话t永远无法析构自己，所以需要将内部的这个指针改为weak_ptr。</li>
  <li>延迟梯度左边的Tx表示发送时间，右边的tx表示接收时间。延迟梯度的计算公式就是：gt(i)=(t(i)-t(i-1))-(T(i)-T(i-1))，实际上就是发送间隔和接收间隔的差值。网络状态良好的情况下，这个值为0，当网络状态变差(发送端速度不变，接收端速度下降)，这个值为正。举个例子：发送端以1mbps的速度发送(每1ms发送1kb数据)，接收端的带宽仅有0.5mbsp，如下图:从第一个1kb到第二个1kb，发送端用时1ms，而接收端需要2ms，梯度=2-1=1ms。观测”延迟梯度”的值，就可以发现发送端和接收端的带宽不对等，需要改变一方的速度。考虑下面这一种情况：发送端与交换机之间的带宽是30mbps，接收端与交换机之间的带宽是10mbps。当发送端以10mbps的速度发送数据时，不考虑其它因素的影响，假设传播时延是10ms，那么任何数据包在10ms内就可以均匀到达接收端。当发送端以大于10mbps的速度发送数据时，由于接收端的网络设备的处理能力只有10mbps，会将无法及时转发的流量缓冲在出口队列中。模拟这下这种情况：发送端以10mbps的速度发送数据，维持100ms，提高速度到16mbps，维持150ms，下降速度到8mbps，并一直保持这个速度。假设发送端发送的单个报文长度为10kbit。前100ms内，接收端的带宽足够，不会有交换机缓冲。接下来的150ms，发送端速度大于接收端的带宽，有一半数据会被缓冲在交换机的队列中，队列长度不断增大，直至丢包。随后发送端速度下降到5mbps，队列中的数据又被不断抽出，直至恢复正常。用以下代码对上述情况进行简单的模拟:发送端std::vector&lt;Packet&gt;BitSender::send(common::Timestampat_time){usingnamespacecommon::rate;usingnamespacecommon::time_interval;//初始化if(!last_sent_time_.is_valid()){last_sent_time_=at_time;}size_tbits_will_send=0;std::vector&lt;Packet&gt;packets;bits_will_send=static_cast&lt;size_t&gt;(bps_.value()*((at_time-last_sent_time_)/1_sec));bits_sent_+=bits_will_send;size_tbits_reamin=bits_will_send;//向上取整longn=std::lround(bits_reamin*1.0/kPacketSize);for(inti=0;i&lt;n;i++){Packetpacket;packet.size=kPacketSize;packet.send_time=at_time;packets.push_back(packet);}last_sent_time_=at_time;returnpackets;}转发端//接受发送端的数据，放到队列中voidBitForwarder::recive(std::vector&lt;Packet&gt;&amp;packets){for(auto&amp;packet:packets){packet.delay=packet.delay+5_ms;//发送端-&gt;转发端传输时延fifo_.push(packet);}}//发送队列中的数据std::vector&lt;Packet&gt;BitForwarder::forward(common::Timestampat_time){size_tbits_will_forward=0;if(!last_forwarded_time_.is_valid()){last_forwarded_time_=at_time;}std::vector&lt;Packet&gt;forward_packets;bits_will_forward=static_cast&lt;size_t&gt;(bps_.value()*((at_time-last_forwarded_time_)/1_sec));bits_forwarded_+=bits_will_forward;size_tbits_remain=bits_will_forward;while(bits_remain&amp;&amp;fifo_.size()){if(fifo_.front().size&lt;=bits_remain){forward_packets.push_back(fifo_.front());bits_remain-=fifo_.front().size;fifo_.pop();}else{break;}}last_forwarded_time_=at_time;returnforward_packets;}接收端voidBitReciver::recive(std::vector&lt;Packet&gt;&amp;packets,common::Timestampat_time){for(auto&amp;packet:packets){packet.delay=packet.delay+5_ms;//转发端-&gt;接收端传输时延packet.recive_time=at_time;}record(packets);//对每个包的发送、接收时间进行记录}主函数intmain(){BitSendersender(0_mbps);BitReciverreciver(10_mbps);BitForwarderforwarder(reciver.bps());constautostart_time=common::Timestamp::now();constautokFirstStageEndTime=start_time+100_ms;constautokSecondStageEndTime=start_time+150_ms;constautokThirdStageEndTime=start_time+300_ms;constautokFirstStageBps=10_mbps;constautokSecondStageBps=16_mbps;constautokThirdStageBps=8_mbps;//粒度是5msautocur_time=start_time;sender.set_bps(kFirstStageBps);while(cur_time&lt;kFirstStageEndTime){autopackets=sender.send(cur_time);forwarder.recive(packets);autopackets_f=forwarder.forward(cur_time);reciver.recive(packets_f,cur_time);cur_time=cur_time+2_ms;//2ms处理间隔(尽量小,来模拟"时时刻刻"都在处理)}sender.set_bps(kSecondStageBps);while(cur_time&lt;kSecondStageEndTime){autopackets=sender.send(cur_time);forwarder.recive(packets);autopackets_f=forwarder.forward(cur_time);reciver.recive(packets_f,cur_time);cur_time=cur_time+2_ms;}sender.set_bps(kThirdStageBps);while(cur_time&lt;kThirdStageEndTime){autopackets=sender.send(cur_time);forwarder.recive(packets);autopackets_f=forwarder.forward(cur_time);reciver.recive(packets_f,cur_time);cur_time=cur_time+2_ms;}return0;}以时间t为横坐标，当前延迟梯度的累计和m(t)为纵坐标:变化方向对上图中的“曲线(实际情况中应该是曲线)”求切线:斜率&gt;0，转发设备中的缓冲队列在增大，如果继续保持这个速度，情况会不断恶化斜率&lt;0，转发设备中的缓冲队列在减小，如果继续保持这个速度，情况会不断改善线性回归TrendingLine模块的任务就是，根据历史的数据(时间和延迟梯度和)，计算当前一小段时间内的”斜率”，也就是”变化方向”，用于给速度控制模块参考信息。线性回归过程主要解决的就是如何通过样本来获取最佳的拟合线。最常用的方法便是最小二乘法，它是一种数学优化技术，它通过最小化误差的平方和寻找数据的最佳函数匹配。最小二乘法代码实现计算延迟梯度时，以5ms为间隔，对达到的数据进行分组(5ms内达到的数据为一组)，论文中是以一帧为间隔。webrtc中的代码不太好懂，我自己的实现(可能也不太好懂)：//对每一个到达的数据进行统计voidTrendingLineFilter::incoming_packet_feedback(int64_tsend_time,int64_trecive_time,size_tsize){(void)size;if(common::TimeDelta(send_time-cur_group_.first_packet_send_time)&gt;kSampleGroupInterval&amp;&amp;cur_group_.initialized()){//新的一组do{if(!prev_group_.initialized()){break;}//计算一组值assert(cur_group_.first_packet_send_time&gt;prev_group_.first_packet_send_time);assert(cur_group_.last_packet_recive_time&gt;prev_group_.last_packet_recive_time);int64_tsend_time_delta=cur_group_.first_packet_send_time-prev_group_.first_packet_send_time;int64_trecive_time_delta=cur_group_.last_packet_recive_time-prev_group_.last_packet_recive_time;int64_tdelta_us=recive_time_delta-send_time_delta;insert_new_sample_and_update(delta_us,recive_time);detect(send_time_delta,recive_time);//...}while(false);prev_group_=cur_group_;cur_group_=TimestampGroup();}if(cur_group_.first_packet_send_time&gt;0){cur_group_.first_packet_send_time=std::min(cur_group_.first_packet_send_time,send_time);}else{cur_group_.first_packet_send_time=send_time;}cur_group_.last_packet_recive_time=std::max(cur_group_.last_packet_recive_time,recive_time);}voidTrendingLineFilter::insert_new_sample_and_update(int64_tdelta_us,int64_tcomplete_time_us){constint64_tdelta_ms=std::lround(delta_us*1.0/1000);int64_tcomplete_time_ms=std::lround(complete_time_us*1.0/1000);first_arrive_time_ms_=std::min(first_arrive_time_ms_,complete_time_ms);acc_delay_+=delta_ms;num_delay_delta_++;num_delay_delta_=std::min&lt;int64_t&gt;(num_delay_delta_,1000);smoothed_delay_=smooth_coeff_*smoothed_delay_+(1-smooth_coeff_)*acc_delay_;sample_points_.push_back({//由于是"差"，所以每一组数据都不会非常大，数值不会溢出，可以放心用于后续的数学计算complete_time_ms-first_arrive_time_ms_,smoothed_delay_});if(sample_points_.size()&gt;=window_size_){/**@explain:*trend可以认为是对当前网络状态的一个反映:(send_rate-capacity)/capacity;*trend&gt;0,网络的排队延迟正在朝着增大的方向发展*trend&lt;0,网络的排队延迟正在朝..减少........*trend=0,没有变化*/cur_trend_=linear_regresion();sample_points_.pop_front();}}//根据数据公式进行计算doubleTrendingLineFilter::linear_regresion(){assert(sample_points_.size()==window_size_);doubletrend=cur_trend_;doublesum_x=0;doublesum_y=0;//TODO:在求平均数这个事情上可以有优化的措施//但是意义并不大for(constauto&amp;point:sample_points_){sum_x+=point.x;sum_y+=point.y;}doublex_avg=sum_x/sample_points_.size();doubley_avg=sum_y/sample_points_.size();doublenumerator=0;doubledenominator=0;for(constauto&amp;point:sample_points_){numerator+=(point.x-x_avg)*(point.y-y_avg);denominator+=(point.x-x_avg)*(point.x-x_avg);}//TODO:C++17的optional可以用在分母为0的处理if(denominator!=0){trend=numerator/denominator;}returntrend;}联系我meemetao@gmail.com</li>
  <li>前言此文算是一个notes，总结一下C++中的各类cast用法和原理。static_cast总结:反转一个定义良好的隐式类型转换static_cast执行关联类型之间的转换，比如一种指针类型向同一个类层次中其它指针类型的转换，或者整数类型向枚举类型的转换，或者浮点类型向整数类型的转换。它还能执行构造函数和转换运算符。同一类层次classB{};classD:publicB{}B和D就叫做同一个类层次。char*ptr_c=nullptr;int*ptr_i=static_cast&lt;int*&gt;(ptr_c);//编译失败B*ptr_b=newB();D*ptr_d=ptr_b;//编译失败D*ptr_d=static_cast&lt;D*&gt;(ptr_b);//fine但是，down_cast是没有任何保证的，程序员必须明白会发生什么事情。整数类型向枚举类型的转换enumclassE:uint8_t{kValue=1};uint8_tv=E::kValue;//编译失败uint8_tv=static_cast&lt;uint8_t&gt;(E::kValue);//fineconst_castconst_cast(expression)参与转换的类型仅在const修饰符及volatile修饰符上有所区别，除此以外new_type和expression的类型是一样。常量指针被转化成非常量的指针，并且仍然指向原来的对象。常量引用被转化成非常量的引用，并且仍然指向原来的对象。dynamic_castdynamic_cast&lt;type*&gt;(e)执行指针或者引用向类层次体系的类型转换，并执行运行时检查。不管是向上或者向下或者向左右都可以调用dynamic_cast。对于upcast，可以但没必要，向上塑性直接写就完事儿了。reinterpret_castreinterpret_cast(expression)这玩意就用的比较少了，和static_cast不一样，只有以下情况可以使用reinterpret_cast:1.表达式是整形、枚举、指针、或者成员指针2.指针和整形互转3.T1*可以和T2*互转4.T1左值可以转化为T2引用5.函数指针可以随便转，不用管类型。这里的函数指针包括类成员函数。相对与static_cast的区别，有以下一个例子:classA{public:intm_a;};classB{public:intm_b;};classC:publicA,publicB{};Cc;printf("%p,%p,%p",&amp;c,reinterpret_cast&lt;B*&gt;(&amp;c),static_cast&lt;B*&gt;(&amp;c));&gt;前两个的输出值是相同的，最后一个则会在原基础上偏移4个字节，这是因为static_cast计算了父子类指针转换的偏移量，并将之转换到正确的地址（c里面有m_a,m_b，转换为B*指针后指到m_b处），而reinterpret_cast却不会做这一层转换。因此,你需要谨慎使用reinterpret_cast。static_pointer_castdynamic_pointer_castconst_pointer_castreinterpret_cast总结上述4个:template&lt;classT,classU&gt;std::shared_ptr&lt;T&gt;static_pointer_cast(conststd::shared_ptr&lt;U&gt;&amp;r)noexcept{autop=static_cast&lt;typenamestd::shared_ptr&lt;T&gt;::element_type*&gt;(r.get());returnstd::shared_ptr&lt;T&gt;(r,p);}template&lt;classT,classU&gt;std::shared_ptr&lt;T&gt;dynamic_pointer_cast(conststd::shared_ptr&lt;U&gt;&amp;r)noexcept{if(autop=dynamic_cast&lt;typenamestd::shared_ptr&lt;T&gt;::element_type*&gt;(r.get())){returnstd::shared_ptr&lt;T&gt;(r,p);}else{returnstd::shared_ptr&lt;T&gt;();}}template&lt;classT,classU&gt;std::shared_ptr&lt;T&gt;const_pointer_cast(conststd::shared_ptr&lt;U&gt;&amp;r)noexcept{autop=const_cast&lt;typenamestd::shared_ptr&lt;T&gt;::element_type*&gt;(r.get());returnstd::shared_ptr&lt;T&gt;(r,p);}template&lt;classT,classU&gt;std::shared_ptr&lt;T&gt;reinterpret_pointer_cast(conststd::shared_ptr&lt;U&gt;&amp;r)noexcept{autop=reinterpret_cast&lt;typenamestd::shared_ptr&lt;T&gt;::element_type*&gt;(r.get());returnstd::shared_ptr&lt;T&gt;(r,p);}</li>
  <li>前言一直以来，字符串编码总是我摸不着头脑。对待字符串编码问题的策略也是简单粗暴，直接规避：一律使用utf-8。但是，猿在码界漂，哪能不挨刀。今天就总结一下字符串编码问题。编码类型介绍ascii编码格式花样很多。由于计算机是老美发明的，因此，最早只有127个字符被编码到计算机中，着127个字符被称为ascii编码集。由于ascii字符集只有127个字符，故只要一个字节就可以表示。else但是，世界上那么多国家、那么多语言，全世界人民都想体验一把先进文化，于是八仙过海，各显神通，日本把日文编码到Shift-jis中，韩国把韩文编码到Euc-kr中。我们国家陆续有gb2312、gbk、gb18030，后者都是对前者的扩展。拿我们汉字举例，汉字有成千上万个，所以一个字节表示不了那么多的汉字，所以就需要多个字节(2个或3个)来表示。unicode大家要是没有一套统一的编码格式的话，还怎么促进文化的交流、各国码农感情的培养。于是，unicode应运而生，unicode把所有语言都统一到一套编码中，这样大家就可以顺畅的交流了。为了表示那么多的语言，unicode也只能采用多字节表示法，就是一个字符用多个字节的数据表示。于是，新的问题又出现了。对于大部分西方国家，他们使用的英语，一个字节就可以表示一个字符。如果使用unicode，那岂不是很浪费空间。于是又有人想出来了一种更佳妙的方式：对unicode继续编码。（可以理解成对unicode压缩编码）也就说，utf-8,utf-16,utf-32是在unicode基础上，对unicode再次编码。以UTF-8来说：UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间：字符asciiunicodeutf-8A01000001000000000100000101000001中?0100111000101101111001001011100010101101这么多编码格式，大家的一个共同点就是：完全对ascii码兼容。也就是说ascii中的’a’，和gb2312中的’a’是同样的表示方法(假设是0x63)。实际环境Linux如果您是在linux上开发，通常是碰不到这些问题的。(没错，我就是舔狗)在Linux上，系统默认就是utf-8格式。这是什么意思？举例来说，当你“touchmain.cpp”这个文件就是采用的utf-8来编码里面的所有数据。当你intmain(){constchar*pstr="中文ABC";printf("%s\n",pstr);return0;}这个pstr中的内容就会以utf-8格式存储。当你:$g++main.cpp-oa.out&amp;./a.out编译器会忠于你的文件编码格式，按此编码格式处理该源文件。pstr中的内容会被取出来放在内存中，并以utf-8格式输出在终端环境上。终端能不能正常显示，就看你的终端能不能支持utf-8。任何的字符串乱码问题，就是上面这三种中的某一个或多个编码格式不一样导致。Windows在windows上，呵呵呵了。中文windows默认采用gb2312格式。举例来说。当你”新建一个文件”，这个文件通常是gb2312格式，如果这个文件只在本地使用，这时候通常是没问题的。但是当你因为某些原因需要使用在windows上使用”unicode”，问题就来了。还是以上面main.cpp为例：1.如果main.cpp为gb2312，用vs编译，pstr为gb2312格式，终端可以显示。2.如果main.cpp为纯unicode，用vs编译，pstr在内存里为gb2312格式，终端可以显示。3.如果main.cpp为utf-8(无bom)，用vs编译，pstr在内存里为utf-8格式，但是终端显示不了中文。4.如果main.cpp为utf-8(bom)，用vs编译，pstr在内存里为gb2312格式，终端可以显示。看到了吧，vs的”睿智”。这个问题如果搭配上”wchar_t”，更加让人恼火。上面的测试可以采用如下程序：voidfoo(unsignedchar*pstr,size_tsize){for(size_ti=0;i&lt;size;i++){printf("%x,",pstr[i]);}printf("\n");}intmain(){std::stringstr="abc中文ABC";char*pstr=const_cast&lt;char*&gt;(str.c_str());foo((unsignedchar*)pstr,sizeofstr);std::wstringwstr=L"abc中文ABC";wchar_t*pwstr=const_cast&lt;wchar_t*&gt;(wstr.c_str());foo((unsignedchar*)pwstr,sizeofstr);return0;}将结果和各个编码表进行对照，既可得出结论。在unicode方面，对windows的批评滔滔不绝，”utf-8everywhere”认为微软在字符串处理上误入歧途，因为他们比别的厂商更早做了决定。微软虽然有理由说，windows先于unicode问世。但是这么多年过去了，windows的API还是不完全支持unicode。windows不遵守基本法，也不是一天两天了，嘻嘻。关于如何在windows处理utf-8，以及对windwos的更多批评，可以从这篇文章起步:utf8everywhere“char与wchar_t，string与wstring如果您不幸遇到了string和wstring方便的困扰，恭喜您。首先，std::string和std::wstring都继承与std::basic_string。只不过std::string的模板参数是char，std::wstring的模板参数是wchar_t。在linux上，wchar_t占用4个字节，windows上则是占用2个字节。他们之间的差别，仅此而已。你如果使用wstring存放字符串，Linux是没有啥问题的，采用utf-32编码wstring。但是如果是windows上，嘻嘻，问题又来了。假设在main.cpp中存放了一个std::wstring=“abc中文”,那么：1.a.cpp如果是gb2312格式，wstring在内存中是unicode格式。2.a.cpp如果是unicode格式，wstring在内存中是unicode格式。3.a.cpp如果是utf-8格式，wstring在内存中是ucs-2be格式。4.a.cpp如果是utf-8-bom格式，wstring在内存中是unicode格式。您肯定还有一个疑惑，关于wstring和string之间的互相转换。那么，您需要确保你非常了解待转换的数据的格式，或者待转换数据仅来自本地。在windows上，windows有一个奇技淫巧：WideCharToMultiByte系列API，通过参数设定你就可以获得你所希望的结果。详见windowsapi说明，如何正确使用，请看：stackoverflow当然，c++标准库也可以做到：std::locale、std::codecvt结合使用。帮组文档utf8everywhere潜谈C/C++编程中的字符编码转换C++字符编码问题探究和中文乱码的产生获得帮助meemetao@gmail.com</li>
  <li>c++中的函数指针(假定在64位机器上)我们知道指针的大小恒定的,跟机器位数有关,32位机下,指针是4字节大小,64位机下指针是8字节大小.但是在C++中,有一个比较特殊的地方是C++的类成员函数指针,它的大小是普通指针的2倍.先看一个实例:voidfoo(void){}classA{public:voidfoo(){}}intmain(){void(*pfun)(void);pfun=foo;void(A::*pMfun)(void);pMfun=&amp;A::foo;std::cout&lt;&lt;"normalfunctionpointersize:"&lt;&lt;sizeof(pfun)&lt;&lt;std::endl;std::cout&lt;&lt;"memberfunctionpointersize:"&lt;&lt;sizeof(pMfun)&lt;&lt;std::endl;return0;}运行结果:normalfunctionpointersize:8memberfunctionpointersize:16证明完毕.下面解释为什么会这样.this指针的调整再看一个例子:classA{public;voidfoo(){//假设我们需要在这里去使用数组astd::cout&lt;&lt;"addrofthis:%x"&lt;&lt;this&lt;&lt;std::endl;}private:inta[4];};classB{public:voidbar(){//假设我们需要在这里去使用数组bstd::cout&lt;&lt;"addrofthis:%x"&lt;&lt;this&lt;&lt;std::endl;}prviate:intb[4];};classC:publicA,B{};intmain(){Cc;c.foo();c.bar();return0;}结果addrofthis:%x0x7ffd30f4ec00addrofthis:%x0x7ffd30f4ec10这时候可以看到,传递给foo和bar函数的this指针是不一样的?为什么会不一样呢?考虑一下函数中的注释.所以调用类成员函数指针时,就需要将this指针进行调整,这个调整的信息在哪里?就在这个函数指针中,所以就需要另外的空间去存放这些信息,这也就是为什么类成员函数指针是16字节的原因,因为多出来的8字节,用于编译期的this指针调整.</li>
</ul>